{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "5Xt7Gwz8Stxa"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Xt7Gwz8Stxa"
      },
      "source": [
        "# Import de fonctions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-9J91SwPO3F"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import adjusted_rand_score as ARI\n",
        "from sklearn.metrics import adjusted_mutual_info_score as AMI\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import v_measure_score\n",
        "from skimage.transform import resize\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy.stats import wasserstein_distance\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import datetime\n",
        "import sys\n",
        "\n",
        "from scipy.ndimage import grey_dilation, grey_erosion\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "import math\n",
        "from math import *\n",
        "\n",
        "\n",
        "# Dataset des chiffres du MNIST\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whj0Wj-NOtWy"
      },
      "source": [
        "# Fonction pour afficher les donn√©es matricielles sous forme d'images\n",
        "def display_image(X, y, n, label=False):\n",
        "    dim = 32\n",
        "    fig, axs = plt.subplots(n, n, figsize=(5,5))\n",
        "\n",
        "    for i in range(n):\n",
        "      for j in range(n):\n",
        "        axs[i,j].imshow(X[j*n+i].reshape((dim,dim)), cmap='gray')\n",
        "        axs[i,j].axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTRQD6hmYJLT"
      },
      "source": [
        "class NTXentLoss(torch.nn.Module):\n",
        "    def __init__(self, device, batch_size, temperature, use_cosine_similarity):\n",
        "        super(NTXentLoss, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.temperature = temperature\n",
        "        self.device = device\n",
        "        self.softmax = torch.nn.Softmax(dim=-1)\n",
        "        self.mask_samples_from_same_repr = self._get_correlated_mask().type(torch.bool)\n",
        "        self.similarity_function = self._get_similarity_function(use_cosine_similarity)\n",
        "        self.criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
        "\n",
        "    def _get_similarity_function(self, use_cosine_similarity):\n",
        "        if use_cosine_similarity:\n",
        "            self._cosine_similarity = torch.nn.CosineSimilarity(dim=-1)\n",
        "            return self._cosine_simililarity\n",
        "        else:\n",
        "            return self._dot_simililarity\n",
        "\n",
        "    def _get_correlated_mask(self):\n",
        "        diag = np.eye(2 * self.batch_size)\n",
        "        l1 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=-self.batch_size)\n",
        "        l2 = np.eye((2 * self.batch_size), 2 * self.batch_size, k=self.batch_size)\n",
        "        mask = torch.from_numpy((diag + l1 + l2))\n",
        "        mask = (1 - mask).type(torch.bool)\n",
        "        return mask.to(self.device)\n",
        "\n",
        "    @staticmethod\n",
        "    def _dot_simililarity(x, y):\n",
        "        v = torch.tensordot(x.unsqueeze(1), y.T.unsqueeze(0), dims=2)\n",
        "        # x shape: (N, 1, C)\n",
        "        # y shape: (1, C, 2N)\n",
        "        # v shape: (N, 2N)\n",
        "        return v\n",
        "\n",
        "    def _cosine_simililarity(self, x, y):\n",
        "        # x shape: (N, 1, C)\n",
        "        # y shape: (1, 2N, C)\n",
        "        # v shape: (N, 2N)\n",
        "        v = self._cosine_similarity(x.unsqueeze(1), y.unsqueeze(0))\n",
        "        return v\n",
        "\n",
        "    def forward(self, zis, zjs):\n",
        "        representations = torch.cat([zjs, zis], dim=0)\n",
        "\n",
        "        similarity_matrix = self.similarity_function(representations, representations)\n",
        "\n",
        "        # filter out the scores from the positive samples\n",
        "        l_pos = torch.diag(similarity_matrix, self.batch_size)\n",
        "        r_pos = torch.diag(similarity_matrix, -self.batch_size)\n",
        "        positives = torch.cat([l_pos, r_pos]).view(2 * self.batch_size, 1)\n",
        "\n",
        "        negatives = similarity_matrix[self.mask_samples_from_same_repr].view(2 * self.batch_size, -1)\n",
        "\n",
        "        logits = torch.cat((positives, negatives), dim=1)\n",
        "        logits /= self.temperature\n",
        "\n",
        "        labels = torch.zeros(2 * self.batch_size).to(self.device).long()\n",
        "        loss = self.criterion(logits, labels)\n",
        "\n",
        "        return loss / (2 * self.batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib.lines import Line2D\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from matplotlib.patches import Patch\n",
        "\n",
        "@torch.no_grad()\n",
        "class SphericalKMeans:\n",
        "    '''\n",
        "    Kmeans clustering algorithm implemented with PyTorch\n",
        "    Parameters:\n",
        "      n_clusters: int,\n",
        "        Number of clusters\n",
        "      max_iter: int, default: 100\n",
        "        Maximum number of iterations\n",
        "      tol: float, default: 0.0001\n",
        "        Tolerance\n",
        "\n",
        "      mode: {'euclidean', 'cosine'}, default: 'euclidean'\n",
        "        Type of distance measure\n",
        "      minibatch: {None, int}, default: None\n",
        "        Batch size of MinibatchKmeans algorithm\n",
        "        if None perform full KMeans algorithm\n",
        "\n",
        "    Attributes:\n",
        "      centroids: torch.Tensor, shape: [n_clusters, n_features]\n",
        "        cluster centroids\n",
        "    '''\n",
        "\n",
        "    def __init__(self, n_clusters, max_iter=100, tol=1e-8, init=\"k_means++\", n_inits=10, mode=\"euclidean\", minibatch=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol\n",
        "        self.mode = mode\n",
        "        self.minibatch = minibatch\n",
        "        self.init = init\n",
        "        self.n_inits = n_inits\n",
        "\n",
        "        self.centroids = None\n",
        "        self.inertia_ = 0\n",
        "\n",
        "    def kmeans_plus_plus(self, x, K):\n",
        "        # Kmeans++ initialization\n",
        "        N, D = x.shape\n",
        "        c = torch.empty(K, D, dtype=x.dtype, device=x.device)\n",
        "        # 1. Choose one center uniformly at random among the data points.\n",
        "        ind = int(torch.floor(torch.rand(1) * N))\n",
        "        c[0, :] = x[ind, :]\n",
        "        # 2. For each data point x not chosen yet, compute D(x)^2,\n",
        "        #    the squared distance between x and the nearest center that has already been chosen.\n",
        "        # N.B. sq_dists is initialized with infinity values and will be updated through iterations\n",
        "        sq_dists = 1 / torch.zeros(N, device=x.device)\n",
        "        # N.B. invarangeN below is used later in step 3\n",
        "        invarangeN = torch.arange(N, 0, -1, device=x.device, dtype=torch.float32)\n",
        "        for k in range(K - 1):\n",
        "            sq_dists = torch.minimum(sq_dists, ((x - c[k, :]) ** 2).sum(-1))\n",
        "            # 3. Choose one new data point at random as a new center,\n",
        "            #    using a weighted probability distribution where a point x\n",
        "            #    is chosen with probability proportional to D(x)^2.\n",
        "            distrib = torch.cumsum(sq_dists, dim=0)\n",
        "            ind = torch.argmax(invarangeN * (float(torch.rand(1)) * distrib[-1] < distrib))\n",
        "            c[k + 1, :] = x[ind, :]\n",
        "        return c\n",
        "\n",
        "    @staticmethod\n",
        "    def cos_sim(a, b):\n",
        "        \"\"\"\n",
        "          Compute cosine similarity of 2 sets of vectors\n",
        "          Parameters:\n",
        "          a: torch.Tensor, shape: [m, n_features]\n",
        "          b: torch.Tensor, shape: [n, n_features]\n",
        "        \"\"\"\n",
        "        a_norm = a.norm(dim=-1, keepdim=True)\n",
        "        b_norm = b.norm(dim=-1, keepdim=True)\n",
        "        a = a / (a_norm + 1e-8)\n",
        "        b = b / (b_norm + 1e-8)\n",
        "        return a @ b.transpose(-2, -1)\n",
        "\n",
        "    @staticmethod\n",
        "    def euc_sim(a, b):\n",
        "        \"\"\"\n",
        "          Compute euclidean similarity of 2 sets of vectors\n",
        "          Parameters:\n",
        "          a: torch.Tensor, shape: [m, n_features]\n",
        "          b: torch.Tensor, shape: [n, n_features]\n",
        "        \"\"\"\n",
        "        assert a.size()[1] == b.size()[1]\n",
        "        assert len(a.size()) == 2 and len(b.size()) == 2\n",
        "        distance_matrix = ((a[:, :, None] - b.t()[None, :, :]) ** 2).sum(1)\n",
        "        return distance_matrix\n",
        "\n",
        "    def soft_sim(self, a, b):\n",
        "        \"\"\"\n",
        "          Compute soft similarity (or minimum distance) of each vector in a with all of the vectors in b\n",
        "          Parameters:\n",
        "          a: torch.Tensor, shape: [m, n_features]\n",
        "          b: torch.Tensor, shape: [n, n_features]\n",
        "        \"\"\"\n",
        "        soft_sim = 1 / self.euc_sim(a, b)\n",
        "        soft_sim = soft_sim / soft_sim.sum(1, keepdim=True)\n",
        "        return soft_sim\n",
        "\n",
        "    def fit(self, X, centroids=None):\n",
        "        \"\"\"\n",
        "          Combination of fit() and predict() methods.\n",
        "          This is faster than calling fit() and predict() separately.\n",
        "          Parameters:\n",
        "          X: torch.Tensor, shape: [n_samples, n_features]\n",
        "          centroids: {torch.Tensor, None}, default: None\n",
        "            if given, centroids will be initialized with given tensor\n",
        "            if None, centroids will be randomly chosen from X\n",
        "          Return:\n",
        "          labels: torch.Tensor, shape: [n_samples]\n",
        "        \"\"\"\n",
        "        batch_size, emb_dim = X.shape\n",
        "        device = X.device.type\n",
        "\n",
        "        centroids_list = []\n",
        "        inertias_list = []\n",
        "        for init in range(self.n_inits):\n",
        "            if centroids is None:\n",
        "                if self.init == \"k_means++\":\n",
        "                    self.centroids = self.kmeans_plus_plus(X, self.n_clusters)\n",
        "                else:\n",
        "                    self.centroids = X[np.random.choice(batch_size, size=[self.n_clusters], replace=False)]\n",
        "            else:\n",
        "                self.centroids = centroids\n",
        "            self.centroids = torch.nn.functional.normalize(self.centroids, dim=1, p=2)\n",
        "\n",
        "            num_points_in_clusters = torch.ones(self.n_clusters, device=device)\n",
        "\n",
        "            for i in range(self.max_iter):\n",
        "                # Expectation\n",
        "                soft_sim_ = self.soft_sim(X, self.centroids)\n",
        "                hard_sim = torch.nn.functional.one_hot(soft_sim_.argmax(1), num_classes=self.n_clusters).float()\n",
        "                c_grad = (hard_sim.t() @ X) / hard_sim.t().sum(1, keepdim=True)\n",
        "                c_grad = torch.nn.functional.normalize(c_grad, dim=1, p=2)\n",
        "\n",
        "                error = (c_grad - self.centroids).pow(2).sum()\n",
        "                if self.minibatch is not None:\n",
        "                    lr = 1 / num_points_in_clusters[:, None] * 0.9 + 0.1\n",
        "                else:\n",
        "                    lr = 1\n",
        "                num_points_in_clusters += hard_sim.sum(0)\n",
        "                self.centroids = (1-lr)*self.centroids + lr*c_grad\n",
        "                self.centroids = torch.nn.functional.normalize(self.centroids, dim=1, p=2)\n",
        "                if error <= self.tol:\n",
        "                    break\n",
        "            soft_sim_ = self.soft_sim(X, self.centroids)\n",
        "            hard_sim = torch.nn.functional.one_hot(soft_sim_.argmax(1), num_classes=self.n_clusters).float()\n",
        "            self.inertia_ = (hard_sim*self.euc_sim(X, self.centroids)).sum()\n",
        "            inertias_list.append(self.inertia_.cpu().numpy())\n",
        "            centroids_list.append(self.centroids)\n",
        "\n",
        "        best_init_idx = np.argmin(inertias_list)\n",
        "        self.inertia_ = inertias_list[best_init_idx]\n",
        "        self.centroids = centroids_list[best_init_idx]\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "          Predict the closest cluster each sample in X belongs to\n",
        "          Parameters:\n",
        "          X: torch.Tensor, shape: [n_samples, n_features]\n",
        "          Return:\n",
        "          labels: torch.Tensor, shape: [n_samples]\n",
        "        \"\"\"\n",
        "        return self.soft_sim(a=X, b=self.centroids).argmax(1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "          Predict the closest cluster each sample in X belongs to\n",
        "          Parameters:\n",
        "          X: torch.Tensor, shape: [n_samples, n_features]\n",
        "          Return:\n",
        "          labels: torch.Tensor, shape: [n_samples]\n",
        "        \"\"\"\n",
        "        return self.soft_sim(a=X, b=self.centroids)\n",
        "\n",
        "    def fit_predict(self, X, centroids=None):\n",
        "        \"\"\"\n",
        "          Perform kmeans clustering\n",
        "          Parameters:\n",
        "          X: torch.Tensor, shape: [n_samples, n_features]\n",
        "        \"\"\"\n",
        "        self.fit(X, centroids)\n",
        "        return self.predict(X)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mf0QgHZbe_a_",
        "outputId": "164778e8-5a37-4a60-f4a7-7eb57c7a190e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
            "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lciw1CKGJJh3"
      },
      "source": [
        "# Define models and datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_k2CjCqIrPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e5b90e8-a1b2-4ac9-dd2f-f6ebbe5a019a"
      },
      "source": [
        "pos_label = 7\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = np.array([np.pad(img, 2) for img in X_train])\n",
        "X_test = np.array([np.pad(img, 2) for img in X_test])\n",
        "\n",
        "X_train = X_train[y_train==7]\n",
        "X_test = X_test[y_test==7]\n",
        "y_train = y_train[y_train==7]\n",
        "y_test = y_test[y_test==7]\n",
        "\n",
        "# flatten the images\n",
        "n_samples_train = len(X_train)\n",
        "X_train = X_train.reshape((n_samples_train, -1))\n",
        "X_train = X_train - np.min(X_train, 1)[:, None]\n",
        "X_train = X_train / np.max(X_train, 1)[:, None]\n",
        "\n",
        "n_samples_test = len(X_test)\n",
        "X_test = X_test.reshape((n_samples_test, -1))\n",
        "X_test = X_test - np.min(X_test, 1)[:, None]\n",
        "X_test = X_test / np.max(X_test, 1)[:, None]\n",
        "\n",
        "X_train = np.array(X_train).astype(np.float)\n",
        "X_test = np.array(X_test).astype(np.float)\n",
        "y_train = np.array(y_train).astype(np.float)\n",
        "y_test = np.array(y_test).astype(np.float)\n",
        "\n",
        "# load ground truth label\n",
        "import json\n",
        "\n",
        "label_mapping_seven = {'No bar':0, 'With bar':1}\n",
        "with open(\"/content/drive/MyDrive/Neurospin/TheÃÄse Robin/UCSL/mnist_labels.json\") as json_file:\n",
        "    ground_truth_dict = json.load(json_file)\n",
        "    y_cluster_test = np.array([label_mapping_seven[ground_truth_dict[key]] for key in ground_truth_dict.keys()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-d45a57ac09e1>:24: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_train = np.array(X_train).astype(np.float)\n",
            "<ipython-input-5-d45a57ac09e1>:25: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  X_test = np.array(X_test).astype(np.float)\n",
            "<ipython-input-5-d45a57ac09e1>:26: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_train = np.array(y_train).astype(np.float)\n",
            "<ipython-input-5-d45a57ac09e1>:27: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_test = np.array(y_test).astype(np.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjoMwW7LVDji"
      },
      "source": [
        "class Erode(object):\n",
        "    \"\"\"Random erode transform\"\"\"\n",
        "    def __init__(self, kernel):\n",
        "        self.kernel = kernel\n",
        "    def __call__(self, x):\n",
        "        x = grey_erosion(x, size=self.kernel)\n",
        "        return torch.tensor(x)\n",
        "\n",
        "class Dilate(object):\n",
        "    \"\"\"Random dilate transform\"\"\"\n",
        "    def __init__(self, kernel):\n",
        "        self.kernel = kernel\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = grey_dilation(x, size=self.kernel)\n",
        "        return torch.tensor(x)\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target, cluster_pseudo_labels=None, test=False):\n",
        "        self.data = data\n",
        "        self.target = torch.from_numpy(target).float()\n",
        "        if cluster_pseudo_labels is not None :\n",
        "          self.cluster_pseudo_labels = cluster_pseudo_labels.float()\n",
        "        else :\n",
        "          self.cluster_pseudo_labels = None\n",
        "        self.transform = transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.RandomResizedCrop(32, scale=(0.75, 1)),  # MORPHO version of PCL\n",
        "                            transforms.RandomRotation(25),\n",
        "                            transforms.RandomApply([Dilate(np.random.randint(2, 4))], p=0.4),  # MORPHO version of PCL\n",
        "                            transforms.RandomApply([Erode(np.random.randint(2, 4))], p=0.4),  # MORPHO version of PCL\n",
        "                            transforms.RandomAffine(10, translate=(0.1, 0.1), shear=0.05),\n",
        "                        ])\n",
        "        self.test = test\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        x = np.reshape(x, (32, 32))\n",
        "        if self.test :\n",
        "          x_1 = torch.tensor(x)[None,:,:].float()\n",
        "        else :\n",
        "          x_1 = self.transform(x)\n",
        "        x_2 = self.transform(x)\n",
        "        y = self.target[index]\n",
        "        if self.cluster_pseudo_labels is not None :\n",
        "          y_pseudo_label = self.cluster_pseudo_labels[index]\n",
        "          return x_1.cuda(), x_2.cuda(), y.cuda(), y_pseudo_label.cuda()\n",
        "        return x_1.cuda(), x_2.cuda(), y.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU9mmuA9Jtyz"
      },
      "source": [
        "# Simple\n",
        "class SimpleConvNet(nn.Module):\n",
        "    def __init__(self, nc, nz, n_clusters, kernel_size=7):\n",
        "        super(SimpleConvNet, self).__init__()\n",
        "        padding = kernel_size // 2\n",
        "        layers = [\n",
        "            nn.Conv2d(nc, 16, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 32, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=kernel_size, padding=padding),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "        ]\n",
        "        self.backbone = nn.Sequential(*layers)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        self.projection_head = nn.Sequential(\n",
        "                nn.Linear(128, hidden_mlp),\n",
        "                nn.BatchNorm1d(hidden_mlp),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Linear(hidden_mlp, output_dim),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # convolutional backbone\n",
        "        encoded_vectors = self.backbone(x)\n",
        "        encoded_vectors = self.avgpool(encoded_vectors)\n",
        "        encoded_vectors = torch.flatten(encoded_vectors, 1).view(encoded_vectors.size(0), -1)\n",
        "\n",
        "        # non linear mlp head\n",
        "        x = self.projection_head(encoded_vectors)\n",
        "        x = nn.functional.normalize(x, dim=1, p=2)\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieVfvGDqXz-c"
      },
      "source": [
        "# PCL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3p7dVEwXCVI"
      },
      "source": [
        "# SimCLR loss\n",
        "def NTXentLoss(z_i, z_j, temperature=0.1, INF=1e8):\n",
        "    N = len(z_i)\n",
        "    z_i = F.normalize(z_i, p=2, dim=-1) # dim [N, D]\n",
        "    z_j = F.normalize(z_j, p=2, dim=-1) # dim [N, D]\n",
        "    sim_zii = (z_i @ z_i.T) / temperature  # dim [N, N] => Upper triangle contains incorrect pairs\n",
        "    sim_zjj = (z_j @ z_j.T) / temperature  # dim [N, N] => Upper triangle contains incorrect pairs\n",
        "    sim_zij = (z_i @ z_j.T) / temperature  # dim [N, N] => the diag contains the correct pairs (i,j) (x transforms via T_i and T_j)\n",
        "    # 'Remove' the diag terms by penalizing it (exp(-inf) = 0)\n",
        "    sim_zii = sim_zii - INF * torch.eye(N, device=z_i.device)\n",
        "    sim_zjj = sim_zjj - INF * torch.eye(N, device=z_i.device)\n",
        "    correct_pairs = torch.arange(N, device=z_i.device).long()\n",
        "    loss_i = F.cross_entropy(torch.cat([sim_zij, sim_zii], dim=1), correct_pairs)\n",
        "    loss_j = F.cross_entropy(torch.cat([sim_zij.T, sim_zjj], dim=1), correct_pairs)\n",
        "    return loss_i + loss_j\n",
        "\n",
        "# PCL loss\n",
        "def PCLLoss(z_i, z_j, prototypes, pseudo_labels, temperatures):\n",
        "    ntx_loss = NTXentLoss(z_i, z_j)\n",
        "    proto_loss = proto_pcl_loss(z_i, pseudo_labels, prototypes, temperatures)\n",
        "    proto_loss += proto_pcl_loss(z_j, pseudo_labels, prototypes, temperatures)\n",
        "    loss = ntx_loss + proto_loss\n",
        "    return loss\n",
        "\n",
        "def proto_pcl_loss(v, pseudo_labels, prototypes, temperatures):\n",
        "    numerator = torch.exp(v @ ((pseudo_labels @ prototypes).T / (temperatures[:, None] * pseudo_labels.T).sum()))\n",
        "    denominator = torch.exp(v @ (prototypes / temperatures[:, None]).sum(0))\n",
        "    loss = numerator / denominator[:, None]\n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "temperature = 0.1\n",
        "alpha = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "id_GVQ_FiRdr",
        "outputId": "467d0476-cbcf-4d9e-c696-c9f174d58d5d"
      },
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 75\n",
        "base_lr = 0.00001\n",
        "\n",
        "# model parameters\n",
        "hidden_mlp = 128\n",
        "output_dim = 128\n",
        "nc = 1\n",
        "n_clusters=2\n",
        "batch_size = 256\n",
        "\n",
        "def momentum_step(m, encoder, momentum_encoder):\n",
        "    '''\n",
        "    Momentum step (Eq (2)).\n",
        "    Args:\n",
        "        - m (float): momentum value. 1) m = 0 -> copy parameter of encoder to key encoder\n",
        "                                      2) m = 0.999 -> momentum update of key encoder\n",
        "    '''\n",
        "    params_q = encoder.state_dict()\n",
        "    params_k = momentum_encoder.state_dict()\n",
        "\n",
        "    dict_params_k = dict(params_k)\n",
        "\n",
        "    for name in params_q:\n",
        "        theta_k = dict_params_k[name]\n",
        "        theta_q = params_q[name].data\n",
        "        dict_params_k[name].data.copy_(m * theta_k + (1 - m) * theta_q)\n",
        "\n",
        "    momentum_encoder.load_state_dict(dict_params_k)\n",
        "\n",
        "    return momentum_encoder\n",
        "\n",
        "for run in range(0, 3) :\n",
        "  # build model\n",
        "  encoder_model = SimpleConvNet(nc, hidden_mlp, output_dim, n_clusters).float().cuda()\n",
        "  teacher_encoder_model = SimpleConvNet(nc, hidden_mlp, output_dim, n_clusters).float().cuda()\n",
        "  teacher_encoder_model = momentum_step(0, encoder_model, teacher_encoder_model)\n",
        "  for param in teacher_encoder_model.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # transform features\n",
        "    encoder_model.eval()\n",
        "    teacher_encoder_model.eval()\n",
        "    X_test_head = []\n",
        "    for img in X_test :\n",
        "      img = img.reshape((32, 32))\n",
        "      img = torch.tensor(img).cuda().float()[None, None,:,:]\n",
        "      head_vector = teacher_encoder_model.forward(img)\n",
        "      X_test_head.append(head_vector)\n",
        "    X_test_head = torch.stack(X_test_head, dim=0)[:, 0]\n",
        "    # transform features\n",
        "    X_train_head = []\n",
        "    for img in X_train :\n",
        "      img = img.reshape((32, 32))\n",
        "      img = torch.tensor(img).cuda().float()[None, None,:,:]\n",
        "      head_vector = teacher_encoder_model.forward(img)\n",
        "      X_train_head.append(head_vector)\n",
        "    X_train_head = torch.stack(X_train_head, dim=0)[:, 0]\n",
        "\n",
        "  # get positive kmeans pseudo labels : Q\n",
        "  KMeans_method = SphericalKMeans(n_clusters=n_clusters).fit(X_train_head)\n",
        "  y_train_kmeans = KMeans_method.predict(X_train_head)\n",
        "  y_test_kmeans = KMeans_method.predict(X_test_head)\n",
        "  prototypes = KMeans_method.centroids\n",
        "  prototypes = nn.functional.normalize(prototypes, dim=1, p=2)\n",
        "\n",
        "  # get y_train and y_test pseudo-labels\n",
        "  y_train_kmeans_numpy = y_train_kmeans.detach().cpu().numpy()\n",
        "  L2_norms = np.linalg.norm(prototypes.cpu().numpy().T[None, :, :] - X_train_head[:, :, None].cpu().numpy(), axis=1)\n",
        "  Z = [np.sum(y_train_kmeans_numpy == cluster) for cluster in range(0, n_clusters)]\n",
        "  temperatures = torch.tensor(\n",
        "      np.array([np.sum(L2_norms[y_train_kmeans_numpy == cluster]) / (Z[i] * log(Z[i] + alpha))\n",
        "                for i, cluster in enumerate(range(0, n_clusters))])).float().cuda()\n",
        "  temperatures = temperatures - temperatures.mean() + temperature\n",
        "\n",
        "  # dataloaders\n",
        "  train_data = MyDataset(X_train, y_train, torch.nn.functional.one_hot(y_train_kmeans, num_classes=n_clusters))\n",
        "  test_data = MyDataset(X_test, y_test, torch.nn.functional.one_hot(y_test_kmeans, num_classes=n_clusters), test=True)\n",
        "  # prepare data loaders\n",
        "  train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, drop_last=True)\n",
        "  test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, drop_last=True)\n",
        "\n",
        "  print('------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "  # specify loss function\n",
        "  optimizer = torch.optim.Adam(encoder_model.parameters(), lr=base_lr)\n",
        "\n",
        "  train_losses = []\n",
        "  test_losses = []\n",
        "\n",
        "  # launch training\n",
        "  for epoch in range(0, n_epochs+1):\n",
        "      # monitor training loss\n",
        "      train_loss = 0.0\n",
        "      test_loss = 0.0\n",
        "\n",
        "      ###################\n",
        "      # train the model #\n",
        "      ###################\n",
        "      encoder_model.train()\n",
        "      for it, data in enumerate(train_loader):\n",
        "          # _ stands in for labels, here no need to flatten images\n",
        "          images_i, images_j, labels, pseudo_labels = data\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          latent_vectors_i = encoder_model.forward(images_i.float())\n",
        "          latent_vectors_j = encoder_model.forward(images_j.float())\n",
        "          # calculate the loss\n",
        "          if epoch > 35:\n",
        "            loss = PCLLoss(latent_vectors_i, latent_vectors_j, prototypes, pseudo_labels, temperatures)\n",
        "          else :\n",
        "            loss = NTXentLoss(latent_vectors_i, latent_vectors_j)\n",
        "          # backward pass: compute gradient of the loss with respect to model parameters\n",
        "          loss.backward()\n",
        "          # perform a single optimization step (parameter update)\n",
        "          optimizer.step()\n",
        "          # update running training loss\n",
        "          train_loss += loss.item()*images_i.size(0)\n",
        "          # clear the gradients of all optimized variables\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "      if epoch <= 35:\n",
        "          teacher_encoder_model = momentum_step(0, encoder_model, teacher_encoder_model)\n",
        "      else:\n",
        "          teacher_encoder_model = momentum_step(0.99, encoder_model, teacher_encoder_model)\n",
        "\n",
        "      ###################\n",
        "      # evaluate the model #\n",
        "      ###################\n",
        "      encoder_model.eval()\n",
        "      with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "          # _ stands in for labels, here no need to flatten images\n",
        "          images_i, images_j, labels, pseudo_labels = data\n",
        "          # clear the gradients of all optimized variables\n",
        "          optimizer.zero_grad()\n",
        "          # forward pass: compute predicted outputs by passing inputs to the model\n",
        "          latent_vectors_i = encoder_model.forward(images_i.float())\n",
        "          latent_vectors_j = encoder_model.forward(images_j.float())\n",
        "          # calculate the loss\n",
        "          if epoch > 35:\n",
        "            loss = PCLLoss(latent_vectors_i, latent_vectors_j, prototypes, pseudo_labels, temperatures)\n",
        "          else :\n",
        "            loss = NTXentLoss(latent_vectors_i, latent_vectors_j)\n",
        "          # update running testing loss\n",
        "          test_loss += loss.item()*images_i.size(0)\n",
        "\n",
        "      # print avg training statistics\n",
        "      train_loss = train_loss/len(train_loader)\n",
        "      test_loss = test_loss/len(test_loader)\n",
        "      #\n",
        "      train_losses.append(train_loss)\n",
        "      test_losses.append(test_loss)\n",
        "      print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "          epoch,\n",
        "          train_loss\n",
        "          ))\n",
        "      print('         \\tTesting Loss: {:.6f}'.format(\n",
        "          test_loss\n",
        "          ))\n",
        "\n",
        "      with torch.no_grad():\n",
        "        # transform features\n",
        "        encoder_model.eval()\n",
        "        teacher_encoder_model.eval()\n",
        "        X_test_head = []\n",
        "        for img in X_test :\n",
        "          img = img.reshape((32, 32))\n",
        "          img = torch.tensor(img).cuda().float()[None, None,:,:]\n",
        "          head_vector = teacher_encoder_model.forward(img.float())\n",
        "          X_test_head.append(head_vector)\n",
        "        X_test_head = torch.stack(X_test_head, dim=0)[:, 0]\n",
        "        # transform features\n",
        "        X_train_head = []\n",
        "        for img in X_train :\n",
        "          img = img.reshape((32, 32))\n",
        "          img = torch.tensor(img).cuda().float()[None, None,:,:]\n",
        "          head_vector = teacher_encoder_model.forward(img.float())\n",
        "          X_train_head.append(head_vector)\n",
        "        X_train_head = torch.stack(X_train_head, dim=0)[:, 0]\n",
        "\n",
        "      # get positive kmeans pseudo labels : Q\n",
        "      KMeans_method = SphericalKMeans(n_clusters=n_clusters).fit(X_train_head)\n",
        "      y_train_kmeans = KMeans_method.predict(X_train_head)\n",
        "      y_test_kmeans = KMeans_method.predict(X_test_head)\n",
        "      prototypes = KMeans_method.centroids\n",
        "      prototypes = nn.functional.normalize(prototypes, dim=1, p=2)\n",
        "\n",
        "      # get y_train and y_test pseudo-labels\n",
        "      y_train_kmeans_numpy = y_train_kmeans.detach().cpu().numpy()\n",
        "      L2_norms = np.linalg.norm(prototypes.cpu().numpy().T[None, :, :] - X_train_head[:, :, None].cpu().numpy(), axis=1)\n",
        "      Z = [np.sum(y_train_kmeans_numpy == cluster) for cluster in range(0, n_clusters)]\n",
        "      temperatures = torch.tensor(\n",
        "          np.array([np.sum(L2_norms[y_train_kmeans_numpy == cluster]) / (Z[i] * log(Z[i] + alpha))\n",
        "                    for i, cluster in enumerate(range(0, n_clusters))])).float().cuda()\n",
        "      temperatures = temperatures - temperatures.mean() + temperature\n",
        "\n",
        "      # dataloaders\n",
        "      train_data = MyDataset(X_train, y_train, y_train_kmeans)\n",
        "      test_data = MyDataset(X_test, y_test, y_test_kmeans, test=True)\n",
        "      # prepare data loaders\n",
        "      train_data = MyDataset(X_train, y_train, torch.nn.functional.one_hot(y_train_kmeans, num_classes=n_clusters))\n",
        "      test_data = MyDataset(X_test, y_test, torch.nn.functional.one_hot(y_test_kmeans, num_classes=n_clusters), test=True)\n",
        "\n",
        "      print(\"KM balanced accuracy score with hand-crafted labels : \",\n",
        "                  max(balanced_accuracy_score(y_cluster_test, y_test_kmeans.detach().cpu().numpy()[:len(y_cluster_test)]),\n",
        "                  balanced_accuracy_score(1-y_cluster_test, y_test_kmeans.detach().cpu().numpy()[:len(y_cluster_test)]))\n",
        "                  )\n",
        "\n",
        "      print('------------------------------------------------------------------')\n",
        "\n",
        "  plt.plot(train_losses, label=\"train\")\n",
        "  plt.plot(test_losses, label=\"test\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "  print('---------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTraining Loss: 3219.347036\n",
            "         \tTesting Loss: 3312.099426\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5588074117203823\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 2950.691833\n",
            "         \tTesting Loss: 3452.632446\n",
            "KM balanced accuracy score with hand-crafted labels :  0.540226735623523\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 \tTraining Loss: 2843.329102\n",
            "         \tTesting Loss: 3566.183655\n",
            "KM balanced accuracy score with hand-crafted labels :  0.572473199301298\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 \tTraining Loss: 2795.291239\n",
            "         \tTesting Loss: 3660.719604\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5826112271808748\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 \tTraining Loss: 2751.218048\n",
            "         \tTesting Loss: 3952.171631\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5929205055313902\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 \tTraining Loss: 2702.876963\n",
            "         \tTesting Loss: 4269.108887\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5910881254923451\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 \tTraining Loss: 2661.060181\n",
            "         \tTesting Loss: 4009.970154\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5944103846285578\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 \tTraining Loss: 2609.041402\n",
            "         \tTesting Loss: 3882.414307\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6093605507415145\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 \tTraining Loss: 2582.289419\n",
            "         \tTesting Loss: 4165.092407\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6078706716443469\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 \tTraining Loss: 2559.866526\n",
            "         \tTesting Loss: 3964.913940\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6145151899167722\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \tTraining Loss: 2519.675639\n",
            "         \tTesting Loss: 4616.719360\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6013974038428606\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 \tTraining Loss: 2481.699412\n",
            "         \tTesting Loss: 4383.091553\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5995650238038155\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 \tTraining Loss: 2445.725922\n",
            "         \tTesting Loss: 4572.150146\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6163475699558174\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 \tTraining Loss: 2430.768819\n",
            "         \tTesting Loss: 4735.373901\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6229920882282427\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 \tTraining Loss: 2402.796478\n",
            "         \tTesting Loss: 4231.188599\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6263143473644552\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 \tTraining Loss: 2385.002248\n",
            "         \tTesting Loss: 4605.947632\n",
            "KM balanced accuracy score with hand-crafted labels :  0.601054902900983\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 \tTraining Loss: 2351.463206\n",
            "         \tTesting Loss: 4727.497437\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6278042264616228\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 \tTraining Loss: 2326.296387\n",
            "         \tTesting Loss: 4454.651489\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6263143473644552\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 \tTraining Loss: 2304.107147\n",
            "         \tTesting Loss: 4457.657593\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6108504298386821\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 \tTraining Loss: 2310.697245\n",
            "         \tTesting Loss: 5068.085083\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5975613932938315\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 \tTraining Loss: 2270.740519\n",
            "         \tTesting Loss: 4946.847900\n",
            "KM balanced accuracy score with hand-crafted labels :  0.604034661095318\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 \tTraining Loss: 2270.355469\n",
            "         \tTesting Loss: 4486.721802\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6178374490529849\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 \tTraining Loss: 2215.552734\n",
            "         \tTesting Loss: 4938.020996\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6161763194848786\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 \tTraining Loss: 2208.572693\n",
            "         \tTesting Loss: 4877.007935\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6283179778744391\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 \tTraining Loss: 2185.726990\n",
            "         \tTesting Loss: 4923.919312\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6110216803096209\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 \tTraining Loss: 2194.050883\n",
            "         \tTesting Loss: 5003.405396\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6091893002705757\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 \tTraining Loss: 2157.850210\n",
            "         \tTesting Loss: 5027.774414\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6171524471692297\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 \tTraining Loss: 2145.243734\n",
            "         \tTesting Loss: 4965.903320\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5865671130595609\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 \tTraining Loss: 2130.607635\n",
            "         \tTesting Loss: 4806.158081\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5829023529814708\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 \tTraining Loss: 2149.649490\n",
            "         \tTesting Loss: 4646.427368\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5938966332157414\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 \tTraining Loss: 2117.512309\n",
            "         \tTesting Loss: 4805.513916\n",
            "KM balanced accuracy score with hand-crafted labels :  0.600198650546289\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31 \tTraining Loss: 2083.915588\n",
            "         \tTesting Loss: 4542.801880\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5902318731376511\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32 \tTraining Loss: 2073.765650\n",
            "         \tTesting Loss: 4928.853027\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5850772339623934\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33 \tTraining Loss: 2060.344243\n",
            "         \tTesting Loss: 5025.438477\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6058670411343632\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34 \tTraining Loss: 2070.848979\n",
            "         \tTesting Loss: 4870.237427\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6140014385039558\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35 \tTraining Loss: 2041.465388\n",
            "         \tTesting Loss: 4923.687500\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6025447819981505\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36 \tTraining Loss: 31807.198568\n",
            "         \tTesting Loss: 4264.872559\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6191560776792137\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37 \tTraining Loss: 4091.283691\n",
            "         \tTesting Loss: 4542.306763\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6307839846559578\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 38 \tTraining Loss: 4068.810160\n",
            "         \tTesting Loss: 4470.954834\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6405795115936568\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 39 \tTraining Loss: 3920.403412\n",
            "         \tTesting Loss: 4402.653564\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6437305202589307\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 40 \tTraining Loss: 3902.817861\n",
            "         \tTesting Loss: 4249.304932\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6452203993560983\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41 \tTraining Loss: 3818.501953\n",
            "         \tTesting Loss: 4167.203613\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6601705654690551\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 42 \tTraining Loss: 3718.944305\n",
            "         \tTesting Loss: 4164.068359\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6634928246052677\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 43 \tTraining Loss: 3674.416870\n",
            "         \tTesting Loss: 4226.027893\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6664725827996028\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 44 \tTraining Loss: 3657.244456\n",
            "         \tTesting Loss: 4136.894104\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6646402027605576\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 45 \tTraining Loss: 3599.603129\n",
            "         \tTesting Loss: 4141.684082\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6679624618967702\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 46 \tTraining Loss: 3489.776988\n",
            "         \tTesting Loss: 4095.463989\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6696235914648765\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 47 \tTraining Loss: 3449.897695\n",
            "         \tTesting Loss: 3971.756287\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6696235914648765\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 48 \tTraining Loss: 3421.801076\n",
            "         \tTesting Loss: 3983.160339\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6696235914648765\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 49 \tTraining Loss: 3332.071950\n",
            "         \tTesting Loss: 3917.538025\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6729458506010892\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 50 \tTraining Loss: 3316.699544\n",
            "         \tTesting Loss: 3920.217590\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6712847210329829\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51 \tTraining Loss: 3264.543223\n",
            "         \tTesting Loss: 3858.559326\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6729458506010892\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 52 \tTraining Loss: 3210.606903\n",
            "         \tTesting Loss: 3778.296387\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6779292393054082\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 53 \tTraining Loss: 3203.268555\n",
            "         \tTesting Loss: 3760.238586\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6812514984416207\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 54 \tTraining Loss: 3146.926178\n",
            "         \tTesting Loss: 3767.885437\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6812514984416207\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 55 \tTraining Loss: 3115.262054\n",
            "         \tTesting Loss: 3770.067810\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6862348871459396\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 56 \tTraining Loss: 3075.285207\n",
            "         \tTesting Loss: 3717.792114\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6759256087954242\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 57 \tTraining Loss: 3073.594625\n",
            "         \tTesting Loss: 3672.909363\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6707709696201665\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 58 \tTraining Loss: 3052.735138\n",
            "         \tTesting Loss: 3645.427673\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6691098400520601\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 59 \tTraining Loss: 3027.879964\n",
            "         \tTesting Loss: 3581.963989\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6656163304449088\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 60 \tTraining Loss: 2980.536316\n",
            "         \tTesting Loss: 3570.053406\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6656163304449088\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61 \tTraining Loss: 2975.519491\n",
            "         \tTesting Loss: 3520.653564\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6656163304449088\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 62 \tTraining Loss: 2960.474335\n",
            "         \tTesting Loss: 3505.628967\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6656163304449088\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 63 \tTraining Loss: 2937.088338\n",
            "         \tTesting Loss: 3511.713013\n",
            "KM balanced accuracy score with hand-crafted labels :  0.667277460013015\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 64 \tTraining Loss: 2932.714712\n",
            "         \tTesting Loss: 3474.974670\n",
            "KM balanced accuracy score with hand-crafted labels :  0.667277460013015\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 65 \tTraining Loss: 2929.083028\n",
            "         \tTesting Loss: 3448.907959\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6639552008768024\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 66 \tTraining Loss: 2891.148549\n",
            "         \tTesting Loss: 3440.145752\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6606329417405898\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 67 \tTraining Loss: 2903.362834\n",
            "         \tTesting Loss: 3481.947754\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6657875809158476\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 68 \tTraining Loss: 2876.593760\n",
            "         \tTesting Loss: 3432.307495\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6657875809158476\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 69 \tTraining Loss: 2895.548503\n",
            "         \tTesting Loss: 3376.603027\n",
            "KM balanced accuracy score with hand-crafted labels :  0.662294071308696\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 70 \tTraining Loss: 2860.842590\n",
            "         \tTesting Loss: 3377.253540\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6624653217796349\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71 \tTraining Loss: 2847.627482\n",
            "         \tTesting Loss: 3363.729309\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6659588313867864\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 72 \tTraining Loss: 2830.617910\n",
            "         \tTesting Loss: 3356.805847\n",
            "KM balanced accuracy score with hand-crafted labels :  0.66429770181868\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 73 \tTraining Loss: 2830.949585\n",
            "         \tTesting Loss: 3392.893188\n",
            "KM balanced accuracy score with hand-crafted labels :  0.66429770181868\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 74 \tTraining Loss: 2822.718953\n",
            "         \tTesting Loss: 3375.452637\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6661300818577252\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 75 \tTraining Loss: 2803.082469\n",
            "         \tTesting Loss: 3333.476746\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6644689522896188\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 \tTraining Loss: 3035.823710\n",
            "         \tTesting Loss: 3336.547668\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5173990478473816\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 2791.253194\n",
            "         \tTesting Loss: 3336.136475\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5861047367880261\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 \tTraining Loss: 2691.399160\n",
            "         \tTesting Loss: 3323.288269\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5731582011850533\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 \tTraining Loss: 2620.669230\n",
            "         \tTesting Loss: 3373.748108\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5746480802822207\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 \tTraining Loss: 2552.861898\n",
            "         \tTesting Loss: 3742.837280\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5739630783984656\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 \tTraining Loss: 2482.748077\n",
            "         \tTesting Loss: 3853.628784\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5741343288694044\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 \tTraining Loss: 2447.872182\n",
            "         \tTesting Loss: 3849.948608\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5696646915779018\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 \tTraining Loss: 2375.953868\n",
            "         \tTesting Loss: 3625.043457\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5728157002431756\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 \tTraining Loss: 2339.649811\n",
            "         \tTesting Loss: 4206.922058\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5827824776518136\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 \tTraining Loss: 2294.658529\n",
            "         \tTesting Loss: 4346.761536\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5800938452580744\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 \tTraining Loss: 2250.361593\n",
            "         \tTesting Loss: 4426.861694\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5798027194574785\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11 \tTraining Loss: 2209.050557\n",
            "         \tTesting Loss: 4339.890625\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6072370449018735\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 12 \tTraining Loss: 2170.016602\n",
            "         \tTesting Loss: 4625.875854\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5661711819707504\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 13 \tTraining Loss: 2153.303507\n",
            "         \tTesting Loss: 4348.892090\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6083844230571633\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 14 \tTraining Loss: 2119.539734\n",
            "         \tTesting Loss: 5167.807495\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5809500976127684\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 15 \tTraining Loss: 2127.466156\n",
            "         \tTesting Loss: 4627.558472\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5972188923519539\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 16 \tTraining Loss: 2099.490987\n",
            "         \tTesting Loss: 4360.144531\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6161763194848786\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 17 \tTraining Loss: 2065.210876\n",
            "         \tTesting Loss: 4495.740967\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6329588656368805\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 18 \tTraining Loss: 2038.330002\n",
            "         \tTesting Loss: 5150.545898\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6121690584649108\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 19 \tTraining Loss: 2025.847173\n",
            "         \tTesting Loss: 5143.922852\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5792889680446621\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 20 \tTraining Loss: 1999.094757\n",
            "         \tTesting Loss: 4932.207153\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5907456245504675\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21 \tTraining Loss: 1973.014893\n",
            "         \tTesting Loss: 5120.413208\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6226495872863651\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 22 \tTraining Loss: 1983.030238\n",
            "         \tTesting Loss: 4961.224487\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6068431688187143\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 23 \tTraining Loss: 1968.375081\n",
            "         \tTesting Loss: 5185.617920\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6189848272082747\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 24 \tTraining Loss: 1948.987640\n",
            "         \tTesting Loss: 4925.372681\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6206459567763811\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 25 \tTraining Loss: 1934.804754\n",
            "         \tTesting Loss: 5087.285400\n",
            "KM balanced accuracy score with hand-crafted labels :  0.655358427235675\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 26 \tTraining Loss: 1938.962372\n",
            "         \tTesting Loss: 4999.761963\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6091893002705757\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 27 \tTraining Loss: 1921.277110\n",
            "         \tTesting Loss: 5034.872192\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5902318731376511\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 28 \tTraining Loss: 1902.218974\n",
            "         \tTesting Loss: 5115.176147\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5940678836866802\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 29 \tTraining Loss: 1877.176036\n",
            "         \tTesting Loss: 5096.215576\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6272904750488064\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 30 \tTraining Loss: 1871.637466\n",
            "         \tTesting Loss: 5036.033447\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6125115594067884\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31 \tTraining Loss: 1858.163610\n",
            "         \tTesting Loss: 5165.159912\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6171524471692297\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 32 \tTraining Loss: 1846.025848\n",
            "         \tTesting Loss: 4965.849365\n",
            "KM balanced accuracy score with hand-crafted labels :  0.604034661095318\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 33 \tTraining Loss: 1841.153000\n",
            "         \tTesting Loss: 5485.187012\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5907456245504675\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 34 \tTraining Loss: 1836.493805\n",
            "         \tTesting Loss: 5211.277954\n",
            "KM balanced accuracy score with hand-crafted labels :  0.5957290132547864\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 35 \tTraining Loss: 1822.056702\n",
            "         \tTesting Loss: 5489.712402\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6043771620371956\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 36 \tTraining Loss: 50694.958537\n",
            "         \tTesting Loss: 4671.331299\n",
            "KM balanced accuracy score with hand-crafted labels :  0.6027160324690892\n",
            "------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 37 \tTraining Loss: 3762.442678\n",
            "         \tTesting Loss: 4595.325806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pcl_normal = []\n",
        "pcl_morpho = [0.6644, ]"
      ],
      "metadata": {
        "id": "89OOV6MTWYy9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}